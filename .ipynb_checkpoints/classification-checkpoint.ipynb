{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Created on Thu May 27 12:34:46 2021\n",
    "\n",
    "#@author: incognito\n",
    "\n",
    "\n",
    "from sklearn.datasets import fetch_openml\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, cross_val_predict\n",
    "from sklearn.base import clone, BaseEstimator\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, precision_recall_curve, roc_curve, roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = fetch_openml('mnist_784', version=1, as_frame=False)\n",
    "\n",
    "X, y = mnist[\"data\"], mnist[\"target\"]\n",
    "some_digit = X[0]\n",
    "some_digit_image = some_digit.reshape(28,28)\n",
    "\n",
    "plt.imshow(some_digit_image, cmap= matplotlib.cm.binary, interpolation=\"nearest\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SPLITTING TRAINING AND TESTING SETS\n",
    "\n",
    "X_train, X_test, y_train, y_test = X[:60000], X[60000:], y[:60000], y[60000:]\n",
    "#shuffling the training set; this will guarantee that all cross-validation folds will be similar\n",
    "shuffle_index = np.random.permutation(60000)\n",
    "X_train, y_train = X_train[shuffle_index], y_train[shuffle_index]\n",
    "\n",
    "#Distinguishing between two classes. 5 or not 5\n",
    "y_train_5 = (y_train == 5)\n",
    "y_test_5 = (y_test == 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stochastic Gradient Classifier'''\n",
    "sgd_clf = SGDClassifier(max_iter=1000, tol=1e-3, random_state=42)\n",
    "sgd_clf.fit(X_train, y_train_5)\n",
    "\n",
    "sgd_clf.predict([some_digit])\n",
    "\n",
    "#IMPLEMENTING CROSS-VALIDATION'''\n",
    "#performing stratified sampling to produce folds that contain a representative ratio of each class.\n",
    "\n",
    "skfolds = StratifiedKFold(n_splits=3, random_state=42)\n",
    "\n",
    "#At each iteration the code creates a clone of the classifier, trains that clone on the training folds,\n",
    "#and makes predictions on the test fold.\n",
    "\n",
    "for train_index, test_index in skfolds.split(X_train, y_train_5):\n",
    "    clone_clf = clone(sgd_clf)\n",
    "    x_train_folds = X_train[train_index]\n",
    "    y_train_folds = (y_train_5[train_index])\n",
    "    x_test_fold = X_train[test_index]\n",
    "    y_test_fold =(y_train_5[test_index])\n",
    "    \n",
    "    clone_clf.fit(x_train_folds, y_train_folds)\n",
    "    y_pred = clone_clf.predict(x_test_fold)\n",
    "    \n",
    "    #it counts the number of correct predictions and outputs the ratio of correct predictions.\n",
    "    \n",
    "    n_correct = sum(y_pred == y_test_fold)\n",
    "    print(n_correct/ len(y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using the cross_val_score() method#\n",
    "cross_val_score(sgd_clf, X_train, y_train_5, cv=3, scoring=\"accuracy\")\n",
    "\n",
    "#A never 5 classifier ccurracy prediction#\n",
    "class Never5Classifier(BaseEstimator):\n",
    "    def fit(self, X, y=None):\n",
    "        pass\n",
    "    def predict(self,X):\n",
    "        return np.zeros((len(X),1), dtype=bool)\n",
    "    \n",
    "never_5_clf = Never5Classifier()\n",
    "cross_val_score(never_5_clf, X_train, y_train_5, cv=3, scoring=\"accuracy\")    \n",
    "\n",
    "#Confusion Matrix#\n",
    "y_train_pred = cross_val_predict(sgd_clf, x_train, y_train_5, cv=3)\n",
    "confusion_matrix(y_train_5, y_train_pred)\n",
    "confusion_matrix(y_train_5, y_train_perfect_predictions)\n",
    "\n",
    "#Precision and Recall#\n",
    "#Precision#\n",
    "precision_score(y_train_5, y_pred)\n",
    "\n",
    "#Recall#\n",
    "recall_score(y_train_5, y_train_pred)\n",
    "\n",
    "#F1#\n",
    "f1_score(y_train_5, y_pred)\n",
    "\n",
    "#DECISION THRESHOLD#\n",
    "#returning a score for each instance\n",
    "#\n",
    "y_scores = sgd_clf.decision_function([some_digit])\n",
    "print(y_scores)\n",
    "#setting a threshold manually#\n",
    "threshold = 200000\n",
    "y_some_digit_pred = (y_scores > threshold)\n",
    "y_scores = cross_val_predict(sgd_clf, X_train, y_train_5, cv=3, method=\"decision_function\")\n",
    "precisions, recalls, thresholds = precision_recall_curve(y_train_5, y_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting precision_recall vs threshold curve#\n",
    "def plot_precision_recall_vs_threshold(precisions, recalls, thresholds):\n",
    "    plt.plot(thresholds, precisions[:-1], \"b--\", label=\"Precisions\")\n",
    "    plt.plot(thresholds, recalls[:-1],\"g-\", label=\"Recall\")\n",
    "    plt.xlabel(\"Threshold\")\n",
    "    plt.legend(loc=\"upper left\")\n",
    "    plt.ylim([0,1])\n",
    "\n",
    "plot_precision_recall_vs_threshold(precisions, recalls, thresholds)\n",
    "plt.show()\n",
    "\n",
    "#Precision ve Recall plot#\n",
    "def plot_precision_vs_recall(precisions, recalls):\n",
    "    plt.plot(recalls[:-1], precisions[:-1], \"b\")\n",
    "    plt.xlabel(\"Recall\")\n",
    "    plt.ylabel(\"Precision\")\n",
    "    #plt.ylim([0,1])\n",
    "\n",
    "plot_precision_vs_recall(precisions, recalls)\n",
    "plt.show()\n",
    "\n",
    "#Getting the highest precision score#\n",
    "90_percent_threshold = thresholds[np.argmax(precisions >= 0.90)]\n",
    "y_train_pred_90 = (y_scores >= 90_percent_threshold)\n",
    "\n",
    "#the precisiion score\n",
    "precision_score(y_train_5, y_train_pred_90)\n",
    "recall_score(y_train_5, y_train_pred_90)\n",
    "\n",
    "#PLotting the ROC curvee#\n",
    "fpr, tpr, thresholds = roc_curve(y_train_5, y_scores)\n",
    "def plot_roc_curve(fpr, tpr, label=None):\n",
    "    plt.plot(fpr, tpr, linewidth=2, label=label)\n",
    "    plt.plot([0,1],[0,1], 'k--')\n",
    "    plt.axis([0,1,0,1])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    \n",
    "plot_roc_curve(fpr, tpr)    \n",
    "plt.show()\n",
    "\n",
    "#gettting the area under the curve score#\n",
    "roc_auc_score(y_train_5, y_scores)\n",
    "\n",
    "#training a Random FOrest#\n",
    "forest_clf = RandomForestClassifier(random_state=42)\n",
    "y_probas_forest = cross_val_predict(forest_clf,  X_train, y_train_5, cv=3, method=\"predict_proba\")\n",
    "y_scores_forest = y_probas_forest[:,1]\n",
    "fpr_forest, tpr_forest, thresholds_forest = roc_curve(y_train_5, y_scores_forest)\n",
    "\n",
    "#comparing respective ROC curves#\n",
    "plt.plot(fpr, tpr, \"b:\",label=\"SGD\")\n",
    "plot_roc_curve(fpr_forest, tpr_forest, \"Random Forest\")\n",
    "plt.legend(loc=\"bottom right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest prediction#\n",
    "y_train_pred_forest = cross_val_predict(forest_clf, X_train, y_train_5, cv=3)\n",
    "\n",
    "precision_score(y_train_5, y_train_pred_forest)\n",
    "recall_score(y_train_5, y_train_pred_forest)\n",
    "\n",
    "#MULTICLASSIFICATION#\n",
    "sgd_clf.fit(X_train, y_train)\n",
    "sgd_clf.predict([some_digit])\n",
    "\n",
    "#scores#\n",
    "some_digit_scores = sgd_clf.decision_function([some_digit])\n",
    "\n",
    "#max score#\n",
    "np.argmax(some_digit_scores)\n",
    "\n",
    "#target classes#\n",
    "sgd_clf.classes_\n",
    "\n",
    "#forcing scikit-learn to use OvO#\n",
    "ovo_clf = OneVsOneClassifier(SGDClassifier(random_state=42))\n",
    "ovo_clf.fit(X_train, y_train)\n",
    "ovo_clf.predict([some_digit])\n",
    "\n",
    "#random forest classifier#\n",
    "forest_clf.fit(X_train, y_train)\n",
    "forest_clf.predict([some_digit])\n",
    "\n",
    "#getting the probabilities of the targets\n",
    "forest_clf.predict_proba([some_digit])\n",
    "\n",
    "#measuring the performance#\n",
    "cross_val_score(sgd_clf, X_train, y_train, cv=3, scoring=\"accuracy\")\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train.astype(np.float64))\n",
    "cross_val_score(sgd_clf, X_train_scaled, y_train, cv=3, scoring=\"accuracy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#ERROR ANALYSIS#\n",
    "y_train_pred = cross_val_predict(sgd_clf, X_train_scaled, y_train, cv=3)\n",
    "conf_mx = confusion_matrix(y_train, y_train_pred)\n",
    "\n",
    "#plotting#\n",
    "plt.matshow(conf_mx, cmap=plt.cm.gray)\n",
    "plt.show()\n",
    "\n",
    "#computinmg the error rates#\n",
    "row_sums = conf_mx.sum(axis=1, keepdims=True)\n",
    "norm_conf_mx = conf_mx / row_sums\n",
    "\n",
    "#filling the diagonals with zeros to keep only the  errors#\n",
    "np.fill_diagonal(norm_conf_mx, 0)\n",
    "plt.matshow(norm_conf_mx, cmap=plt.cm.gray)\n",
    "plt.show()\n",
    "\n",
    "#analysing the 3/5 errror#\n",
    "cl_a, cl_b = 3,5\n",
    "X_aa = X_train[(y_train == cl_a) & (y_train_pred == cl_a)]\n",
    "X_ab = X_train[(y_train == cl_a) & (y_train_pred == cl_b)] \n",
    "X_ba = X_train[(y_train == cl_b) & (y_train_pred == cl_a)]\n",
    "X_bb = X_train[(y_train == cl_b) & (y_train_pred == cl_b)]\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.subplot(221); plot_digits(X_aa[:25], images_per_row=5)\n",
    "plt.subplot(222); plot_digits(X_ab[:25], images_per_row=5)\n",
    "plt.subplot(223); plot_digits(X_bb[:25], images_per_row=5)\n",
    "plt.subplot(224); plot_digits(X_bb[:25], images_per_row=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Measuring the perfomance'''\n",
    "y_train_knn_pred = cross_val_predict(knn_clf, X_train, y_train, cv=3)\n",
    "f1_score(y_train, y_train_knn_pred, average=\"macro\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MULTIOUTPUT CLASSIFICATION#\n",
    "#adding noise to their pixel intensities#\n",
    "noise = rnd.randint(0,100,(len(X_train),784))\n",
    "noise = rnd.randint(0,100,(len(X_test),784))\n",
    "X_train_mod = X_train + noise\n",
    "X_test_mod = X_test + noise\n",
    "y_train_mod = X_train\n",
    "y_test_mod = x_test\n",
    "knn_clf.fit(X_train_mod, y_train_mod)\n",
    "clean_digit = knn_clf.predict([X_test_mod[some_index]])\n",
    "plot_digit(clean_digit)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
